---
title: "Final Project"
author: "Francisco Robles"
date: "April 27, 2019"
output:
  pdf_document: default
  html_document: default
---

The topic dataset that I chose was a Grad School Admissions data set that had each student's GRE Score, their college GPA, and the School Tier that they went to (1 being the best and 4 being the worse). The data was collected from 400 students. I'm not sure how the data was collected, as I had this data set from a previous class that I found and it was just given to us. The question that I want to answer is can we use someone's GRE Score, GPA, and School Tier to predict whether or not they got accepted into grad school. I will be using a logistic regression model to see if we can come up with a way to try and precit the admission to grad school or not.
```{r include=FALSE}
library(tidyverse)
df = read_csv('../../../Data_Course/Data/GradSchool_Admissions.csv')
```




```{r eval=FALSE, include=FALSE}
glimpse(df)
```




Lets try and see if we can visualize this data well.

```{r echo=FALSE}
ggplot(df, aes(gpa, admit, color = factor(rank), size = gre)) +
  geom_jitter(width = 0, height = .1) +
  scale_size_continuous(range = c(1,3), guide = 'none') +
  labs(x = 'GPA', y = 'Admitted?', color = 'School Tier',
       title = 'Grad School Admission vs. GPA by School Tier')
ggplot(df, aes(gre, admit, color = factor(rank), size = gpa)) +
  geom_jitter(width = 0, height = .1) +
  scale_size_continuous(range = c(1,3), guide = 'none') +
  labs(x = 'GRE Score', y = 'Admitted?', color = 'School Tier',
       title = 'Grad School Admission vs. GRE Score by School Tier')
```

It's tough to see just visually how the different variables effect whether you get into grad school or not. What would be the best is if we can see almost a clear point where they went from not being accepted (0 for admit) to being admitted (1 for admit). It does just seem to show that the higher GRE and higher GPA seem to have a better chance at getting in, which makes sense.





```{r include=FALSE}
fun.LogReg = function(data, group, vars, cut.off){
  require(tidyverse)
  # Splitting variables vector
  vars.plus = NULL
  for(i in 1:length(vars)){
    vars.plus = paste(vars.plus, vars[i], sep = '+')
  }
  vars.plus = substr(vars.plus, 2, nchar(vars.plus))
  
  # Creating formula variable
  formula = paste0(group, rawToChar(as.raw(126)), vars.plus)
  
  # Full summary of data
  full.mod = glm(formula, data = data, family = binomial(link = 'logit'))
  full.summ = summary(full.mod)
  conc = survival::concordance(full.mod)
  
  # Leave one out model
  pred = NULL
  results = NULL
  for(i in 1:nrow(data)){
    test = data[i,]
    train = data[-i,]
    train.mod = glm(formula, data = train, family = binomial(link = 'logit'))
    pred[i] = predict(train.mod, type = 'response', newdata = test)
  }
  results = ifelse(pred > cut.off, 1, 0)
  
  # Sensitivity and everything
  fication = table(pull(data, group), ifelse(pred > cut.off, 1, 0))
  rownames(fication) = c('No', 'Yes')
  colnames(fication) = c('Pred No', 'Pred Yes')
  
  acc = (fication[1] + fication[4]) / nrow(data)
  sens = fication[4] / (fication[2] + fication[4])
  specif = fication[1] / (fication[1] + fication[3])
  
  chisq.stat = full.summ$null.deviance - full.summ$deviance
  chisq.p = pchisq(chisq.stat, 1)
  aic.val = full.summ$aic
  conc.val = conc$concordance
  comb = c(Chi.Sq.Value = chisq.stat, Chi.Sq.P = chisq.p, AIC = aic.val, Concordance = conc.val, 
           Accuracy = acc, Sensitivity = sens, Specificity = specif)
  
  # ROC Curve
  test.cut = seq(0,1,.01)
  test.diag = matrix(NA, 101, 5)
  for(i in 1:101){
    test.tab = table(pull(data, group), ifelse(pred > test.cut[i], 1, 0))
    test.acc = (test.tab[1] + test.tab[4]) / nrow(data)
    test.sens = test.tab[4] / (test.tab[2] + test.tab[4])
    test.specif = test.tab[1] / (test.tab[1] + test.tab[3])
    test.add = test.sens + test.specif
    test.comb = c(test.cut[i], test.acc, test.sens, test.specif, test.add)
    test.diag[i,] = test.comb
  }
  test.diag = as.data.frame(test.diag)
  colnames(test.diag) = c('Cut_Off', 'Accuracy', 'Sensitivity', 'Specificity', 'Sens + Specif')
  
  line.seg = test.diag %>%
    group_by(Specificity)%>%
    summarize(y_val = min(Sensitivity))  %>%
    mutate(x_val = 1 - Specificity) %>%
    select(x_val, y_val) %>%
    arrange(x_val) %>%
    slice(-n())
  line.seg = cbind.data.frame(line.seg, line.seg$x_val, c(line.seg$y_val[2:nrow(line.seg)], 1), 
                              c(line.seg$x_val[2:nrow(line.seg)], 1))
  colnames(line.seg) = c('x_start', 'y_start', 'x_end', 'y_end', 'x_end_two')
  
  ROC = ggplot(test.diag, aes(1 - Specificity, Sensitivity)) +
    geom_point()
  for(i in 1:(nrow(line.seg) - 1)){
    ROC = ROC +
      geom_segment(aes(x = x_start, y = y_start, xend = x_end, yend = y_end), data = line.seg) +
      geom_segment(aes(x = x_start, y = y_end, xend = x_end_two, yend = y_end), data = line.seg)
  }
  ROC = ROC +
    geom_abline(aes(intercept = 0, slope = 1, color = 'red')) +
    geom_segment(aes(x = 0, y = 0, xend = 0, yend = line.seg[1,2])) +
    labs(title = 'ROC Curve') +
    theme(plot.title = element_text(size = 20, face = 'bold', hjust = 0.5),
          legend.position = 'none')
  
  # return list
  Model.list = list()
  Model.list[['Model']] = full.mod
  Model.list[['Summary']] = full.summ
  Model.list[['Concordance']] = conc
  Model.list[['Probability']] = full.mod$fitted
  
  loo.list = list()
  loo.list[['Probability']] = pred
  loo.list[['Predicted_Group']] = results
  class.list = list()
  class.list[['Table']] = fication
  class.list[['Diagnostic']] = comb
  class.list[['Full_Diagnostic']] = test.diag
  loo.list[['Classification']] = class.list
  
  plots.list = list()
  plots.list[['ROC']] = ROC
  scatter.resub.list = list()
  scatter.loo.list = list()
  data = cbind.data.frame(data, Pred.resub = full.mod$fitted)
  for(i in vars){
    scatter.resub.list[[i]] = ggplot(data, aes_string(i, 'Pred.resub')) +
      geom_point()
  }
  data = cbind.data.frame(data, Pred.loo = pred)
  for(i in vars){
    scatter.loo.list[[i]] = ggplot(data, aes_string(i, 'Pred.loo')) +
      geom_point()
  }
  plots.list[['Scatter_Resub']] = scatter.resub.list
  plots.list[['Scatter_LOO']] = scatter.loo.list
  plots.list[['Data_for_Plots']] = data
  
  full.list = list()
  full.list[['Model']] = Model.list
  full.list[['LOO']] = loo.list
  full.list[['Plots']] = plots.list
  
  
  return(full.list)
}
```
Lets run our first model and see how well it does
```{r warning=FALSE}
grad_mod = fun.LogReg(df, 'admit', c('gre', 'gpa', 'rank'), .5)
grad_mod$Plots$ROC
```

So for an ROC plot, we are looking for a place where we can see a long vertical line, and we want to choose the point at the top of that vertical line. This one isn't super clear, but the point we want to choose is where the point is at .64 Sensitivity and .65 for Specificity. The .64 Sensitivity tells us that we can identify the people who did get into grad school 64% of the time, and the .65 for Specificity tells us that we can identify the people that got rejected from grad school 65% of the time. This is better than the 50/50 of us just randomly guessing.

```{r eval=FALSE, include=FALSE}
grad_mod$LOO$Classification$Full_Diagnostic
```
We are then going to use that point that we just identified to come up with a cut-off point for our probability. It may seem like you would just say if our model says that you have a 50% chance of gettting in to grad school, we will predict that you do, but that isn't always the best case. That point actually corresponds to a cut-off of .33, meaning that if our model predicts you have over a 33% chance of being admitted to grad school, we will predict that you do make it in.





```{r}
grad_mod2 = fun.LogReg(df, 'admit', c('gre', 'gpa', 'rank'), .33)
```
This model is now using the .33 cut-off. Lets see how our model ended up turning out

```{r echo = FALSE}
grad_mod2$Model$Summary
```
The main thing we need to focus on is the 'Estimate' column. Since each of our rows has at least 1 asterik next to it, it means that each of our predictors (GRE Score, GPA, and School Tier) are important in trying to predict whether students get admitted. If you look at the 'Estimate' column, since GRE and GPA are both positive numbers, it means that people are more likely to get admitted with higher GRE or higher GPA, which makes sense. Since the rank estimate is negative, it means that studnet from lower tier schools have a tougher time getting admitted to grad school.




Let's take a look at how well our model predicted the 400 students from our data set.
```{r echo = FALSE}
grad_mod2$LOO$Classification$Table
```
We mainly want to be on that diagonal line from top left to bottom right (each one on the diagonal means that we predicted correctly). The ones that are not on the diagonal line are ones we didn't predict right.

```{r echo = FALSE}
grad_mod2$LOO$Classification$Diagnostic[5:7]
```
This shows us our Sensitivity and Specificity, both of which we talked about above. It also shows us our accuracy as well (how often we predicted correctly).



To get a better idea about how our model can predict, we can try a couple of examples. The first example we will look at is the worst case scenario for getting in. I will use getting a GRE score of 220 and a GPA of 2.26, since those were the minimums from our data, and have them come from a very low tier school.
```{r echo = FALSE}
worst.odds = exp(grad_mod2$Model$Model$coefficients%*%c(1, 220, 2.26, 4))
worst.prob = worst.odds / (1 + worst.odds)
worst.prob
```
This means that the lowest probability that this model will give us (with still using observations with our data), is a 3% chance of getting in.

The best case scenario would be getting a GRE score of 800, a GPA of 4.0 , and coming from a very high tier school.
```{r echo = FALSE}
best.odds = exp(grad_mod2$Model$Model$coefficients%*%c(1, 800, 4, 1))
best.prob = best.odds / (1 + best.odds)
best.prob
```
This means that the best that this model can predict is that you have a 72% of getting admitted to grad school.



To sum up, I think this model can work really well in trying to predict if a student will get in to grad school or not. It seems that all three of these variables really do matter and how much they do end up mattering. You can also see things like that 1 point of your GPA is worth more than going to a school tier lower (A 3.0 at a Tier 1 School has a less of a chance of getting accepted than a 4.0 at a Tier 2 School) or that 1 point of GPA is worth about as much as 340 points on your GRE.